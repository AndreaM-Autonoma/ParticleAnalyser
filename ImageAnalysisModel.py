import os
# if using Apple MPS, fall back to CPU for unsupported ops
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
import torch
from datetime import datetime
import sys
import ParticleSegmentationModel as psa
import ImageProcessingModel as ip
import logger_config
import sizeAnalysisModel as sa
import ContainerScalerModel as cs


class ImageAnalysisModel:
    def __init__(self, image_folder_path, containerWidth, sampleID=None, ):
        """
        Initializes the ImageAnalysisModel with an image folder path and container width. 
        Sets up the sample ID, image processor, and container scaler.
        
        Inputs:
        - image_folder_path: Path to the folder containing images for analysis.
        - containerWidth: Width of the container used for scaling.
        
        Output: None
        """
        self.sampleID = sampleID if sampleID else os.path.basename(image_folder_path)
        self.imageProcessor = ip.ImageProcessingModel(image_folder_path, self.sampleID)  
        self.imagePath = self.imageProcessor.getImagePath()
        self.Scaler = cs.ContainerScalerModel(containerWidth)
        self.Scaler.updateScalingFactor(self.imageProcessor.getWidth(),containerWidth)

        self.diameter_threshold =100000 #10cm
        self.folder_path=image_folder_path
        self.analysisTime = 0
        self.p = None

    def analysewithCV2(self):
        self.csv_filename = os.path.join(self.folder_path, f"{self.sampleID}.csv")
        self.p.generate_with_cv2(self.csv_filename)
    def showImage(self):
        """
        Displays the processed image using the ImageProcessingModel.
        
        Input: None
        Output: Shows the image.
        """
        self.imageProcessor.showImage()

    def showMasks(self):
        """
        Displays the masks generated by the ParticleSegmentationModel, if available.
        
        Input: None
        Output: Shows mask visualization.
        """
        self.p.visualise_masks()

    def setBins(self, bins):
        """
        Sets the number of bins in the ParticleSegmentationModel based on input.

        Inputs:
        - bins: List of bin boundaries.
        
        Output: None
        """
        if self.p is not None:
            self.numberofBins = len(bins)
            self.p.bins = bins

    def loadModel(self, checkpoint_folder):
        """
        Loads the ParticleSegmentationModel with a specified checkpoint.

        Input:
        - checkpoint_folder: Path to the folder containing model checkpoint.
        
        Output: None
        """
        def loadSamModel(checkpoint_folder):
            os.makedirs(checkpoint_folder, exist_ok=True)
            checkpoint_filename = "sam2.1_hiera_large.pt"  # SAM2
            CHECKPOINT_PATH = os.path.join(checkpoint_folder, checkpoint_filename)
            return CHECKPOINT_PATH

        CHECKPOINT_PATH = loadSamModel(checkpoint_folder)
        self.p = psa.ParticleSegmentationModel(self.imagePath, CHECKPOINT_PATH, self.Scaler.scalingFactor)

    def analyseParticles(self, checkpoint_folder, testing):
        """
        Analyzes particles in the image by generating masks using the model, and calculates analysis time.

        Inputs:
        - checkpoint_folder: Path to the model checkpoint.
        - testing: Boolean flag to enable test mode.
        
        Output: None
        """
        def calculateAnalysisTime(duration):
            total_seconds = duration.total_seconds()
            minutes = int(total_seconds // 60)
            seconds = total_seconds % 60
            self.analysisTime = f"PT{minutes}M{seconds:.1f}S"

        self.loadModel(checkpoint_folder)
        if testing:
            self.p.testing_generate_mask()
        else:
            self.p.generate_mask()
        
        calculateAnalysisTime(self.p.getExecutionTime())
        self.p.setdiameter_threshold(self.diameter_threshold)

    def savePsdData(self):
        """
        Saves particle size distribution (PSD) data to a text file.

        Input: None
        Output: Saves PSD data to a TXT file.
        """
        self.p.get_psd_data()
        self.distributions_filename = os.path.join(self.folder_path, f"{self.sampleID}_distribution.txt")
        self.p.save_psd_as_txt(self.sampleID, self.folder_path)
        print(f"--> PSD data saved as TXT file: {self.distributions_filename}")

    def saveResults(self, bins):
        """
        Saves particle segmentation results to CSV and distribution files after setting bins.

        Input:
        - bins: List of bin boundaries for the segmentation model.
        
        Output: Saves results to CSV and distribution files.
        """
        self.setBins(bins)
        if self.imageProcessor is None:
            raise ValueError("Image is not initialised")

        self.folder_path = self.imageProcessor.getImageFolder()
        self.csv_filename = os.path.join(self.folder_path, f"{self.sampleID}.csv")
        self.p.setdiameter_threshold(self.diameter_threshold)
        self.p.save_masks_to_csv(self.csv_filename)
        print(f"--> Masks saved to CSV file: {self.csv_filename}")

        self.savePsdData()
        
    def formatResults(self):
        """
        Formats and displays analysis results, and saves formatted results as XML.

        Input: None
        Output: Prints formatted results and saves them to an XML file.
        """
        self.totArea = self.p.get_totalArea()
        print("-----------------------------------------------")
        print("Sample ID:", self.sampleID)
        print(f"Total Area: {self.totArea} um2")
        print(f"Total Area: {self.totArea / 100_000_000} cm2")
        print("Scaling Factor:", self.Scaler.scalingFactor)
        print("Scaling Number:", self.Scaler.scalingNumber)
        self.intensity = self.imageProcessor.getIntensity()
        print("Intensity:", self.intensity)
        print("Scaling Stamp:", self.Scaler.scalingStamp)
        print("Analysis Time:", self.analysisTime)
        print("Number of Particles:", self.numberofBins)
        print("Diameter Threshold:", self.p.diameter_threshold)
        print("Circularity Threshold:", self.p.circularity_threshold)
        print("-----------------------------------------------")
        print(f"CSV file: {self.csv_filename}")
        
        formatter = sa.sizeAnalysisModel(self.sampleID, self.csv_filename, self.distributions_filename,
                                         self.totArea, self.Scaler.scalingNumber,
                                         self.Scaler.scalingFactor, self.Scaler.scalingStamp,
                                         self.intensity, self.analysisTime, self.p.diameter_threshold,
                                         self.p.circularity_threshold)
        formatter.save_xml()
    
    def saveSegments(self):
        """
        Saves segment data as JSON for later use.

        Input: None
        Output: Saves segment data to JSON file.
        """
        self.p.setdiameter_threshold(self.diameter_threshold)
        self.json_filename = os.path.join(self.folder_path, f"{self.sampleID}_segments.txt")
        self.p.save_segments(self.json_filename)
        print(f"Saving segments in {self.json_filename}")
    
    def loadSegments(self, checkpoint_folder, bins):
        """
        Loads segments from a JSON file and saves them to CSV and distribution files, useful for non-GPU environments.

        Inputs:
        - checkpoint_folder: Path to the model checkpoint.
        - bins: List of bin boundaries for the segmentation model.
        
        Output: Saves segment data to CSV and distribution files.
        """
        try:
            self.setFolderPath()
            self.json_masks_filename = os.path.join(self.folder_path, f"{self.sampleID}_segments.txt")
            
            if not os.path.exists(self.json_masks_filename):
                raise FileNotFoundError(f"The file {self.json_masks_filename} was not found.")
            
            self.loadModel(checkpoint_folder)
            self.setBins(bins)
            self.csv_filename = os.path.join(self.folder_path, f"{self.sampleID}.csv")
            self.p.setdiameter_threshold(self.diameter_threshold)
            self.p.save_segments_as_csv(self.json_masks_filename, self.csv_filename)
            self.savePsdData()
        
        except FileNotFoundError as e:
            raise e
        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")

    def setFolderPath(self):
        """
        Sets the folder path for saving results, based on the initialized image processor.

        Input: None
        Output: Sets self.folder_path based on image folder path.
        """
        if self.imageProcessor is not None:
            self.folder_path = self.imageProcessor.getImageFolder()
        else:
            raise ValueError("Image not initialized. Please ensure that 'imageProcessor' is properly initialized.")
    
    def crop_image(self):
        self.imageProcessor.cropImage()
        self.imagePath=self.imageProcessor.getImagePath()
        self.Scaler.updateScalingFactor(self.imageProcessor.getWidth())
    
    def evenLighting(self):
        self.imageProcessor.even_out_lighting()
        self.imagePath=self.imageProcessor.getImagePath()
        self.Scaler.updateScalingFactor(self.imageProcessor.getWidth())
        
    def overlayImage(self):
        """
        Calls the ImageProcessingModel's overlayImage function to overlay the same picture 10 times and 
        reducing the size of the image if it is bigger than 8MB

        Input: None
        Output: lighter PNG file and containing the same image overlayed 10 times
        """
        self.imageProcessor.overlayImage()
        self.imagePath=self.imageProcessor.getImagePath()
        self.Scaler.updateScalingFactor(self.imageProcessor.getWidth())

